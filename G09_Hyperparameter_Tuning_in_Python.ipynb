{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b46b3d",
   "metadata": {},
   "source": [
    "# Random Forest Hyperparameter Tuning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2e670",
   "metadata": {},
   "source": [
    "Random Forest is one of the most popular machine learning algorithms used for both classification and regression tasks. It works by building multiple decision trees and combining their outputs to improve accuracy and control overfitting. While Random Forest is a robust model, fine-tuning its hyperparameters such as the number of trees, maximum depth and feature selection can improve its prediction and performance.\n",
    "\n",
    "### Random Forest Hyperparameter\n",
    "\n",
    "* **n_estimators:** The number of trees in the forest. More trees can improve performance but also increase computation time.\n",
    "* **max_depth:** The maximum depth of each tree. Limiting depth can prevent overfitting.\n",
    "* **min_samples_split:** The minimum number of samples required to split an internal node. Higher values prevent overfitting.\n",
    "* **min_samples_leaf:** The minimum number of samples required to be at a leaf node. This can also help in reducing overfitting.\n",
    "* **max_features:** The number of features to consider when looking for the best split. It can be set to 'auto', 'sqrt', 'log2' or a specific number.\n",
    "* **bootstrap:** Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree.\n",
    "\n",
    "## Random Forest Hyperparameter Tuning using Sklearn\n",
    "\n",
    "Scikit-learn offers tools for hyperparameter tuning which can help improve the performance of machine learning models. Hyperparameter tuning involves selecting the best set of parameters for a given model to maximize its efficiency and accuracy. We will explore two commonly used techniques for hyperparameter tuning: GridSearchCV and RandomizedSearchCV.\n",
    "\n",
    "Both methods are essential for automating the process of fine-tuning machine learning models and we will examine how each works and when to use them. Below is the code with random forest working on heart disease prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6c65a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       112\n",
      "           1       0.90      0.78      0.84       145\n",
      "\n",
      "    accuracy                           0.83       257\n",
      "   macro avg       0.83      0.84      0.83       257\n",
      "weighted avg       0.84      0.83      0.83       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = \"https://raw.githubusercontent.com/itsluckysharma01/Datasets/refs/heads/main/gfg_heart.csv\"\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "data = pd.read_csv(dataset)\n",
    "data.head(7)\n",
    "\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_features=\"sqrt\", \n",
    "    max_depth=6, \n",
    "    max_leaf_nodes=6\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7266080f",
   "metadata": {},
   "source": [
    "The classification report shows that the model has an accuracy of 84% with good precision for class 1 (0.90) but slightly lower precision for class 0 (0.77) and a recall of 0.87 for class 0. This suggests that fine-tuning hyperparameters such as n_estimators and max_depth could help improve the performance especially for class 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f041f0",
   "metadata": {},
   "source": [
    "## 1. Hyperparameter Tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01a6d2",
   "metadata": {},
   "source": [
    "First let's use GridSearchCV to obtain the best parameters for the model. It is a hyperparameter tuning method in Scikit-learn that exhaustively searches through all possible combinations of parameters provided in the param_grid. For that we will pass RandomForestClassifier() instance to the model and then fit the GridSearchCV using the training data to find the best parameters.\n",
    "\n",
    "* **param_grid:** A dictionary containing hyperparameters and their possible values. GridSearchCV will try every combination of these values to find the best-performing set of hyperparameters.\n",
    "* **grid_search.fit(X_train, y_train):** This trains the model on the training data (X_train, y_train) for every combination of hyperparameters defined in param_grid.\n",
    "* **grid_search.best_estimator_:** After completing the grid search, this will print the RandomForest model that has the best combination of hyperparameters from the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d254cbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ipython-input-3779764764.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3779764764.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    grid_search.fit(X_train, y_train)col\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)col\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Estimator:\", grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8135632",
   "metadata": {},
   "source": [
    "Updating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea910c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       113\n",
      "           1       0.87      0.76      0.81       144\n",
      "\n",
      "    accuracy                           0.80       257\n",
      "   macro avg       0.80      0.81      0.80       257\n",
      "weighted avg       0.81      0.80      0.80       257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_grid = RandomForestClassifier(max_depth=3,\n",
    "                                    max_features=\"log2\",\n",
    "                                    max_leaf_nodes=3,\n",
    "                                    n_estimators=50)\n",
    "model_grid.fit(X_train, y_train)\n",
    "y_pred_grid = model.predict(X_test)\n",
    "print(classification_report(y_pred_grid, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ff1bf",
   "metadata": {},
   "source": [
    "## 2. Hyperparameter Tuning using RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a6946",
   "metadata": {},
   "source": [
    "RandomizedSearchCV performs a random search over a specified parameter grid. It randomly selects combinations and evaluates the model often leading to faster results especially when there are many hyperparameters.\n",
    "\n",
    "Now let's use RandomizedSearchCV to obtain the best parameters for the model. For that we will pass RandomFoestClassifier() instance to the model and then fit the RandomizedSearchCV using the training data to find the best parameters.\n",
    "\n",
    "* **param_grid** specifies the hyperparameters that you want to tune similar to the grid in GridSearchCV.\n",
    "* **fit(X_train, y_train)** trains the model using the training data.\n",
    "* **best_estimator_** shows the model with the best combination of hyperparameters found by the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30576959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                                   param_grid)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435bb815",
   "metadata": {},
   "source": [
    "Updating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4abf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_random = RandomForestClassifier(max_depth=3,\n",
    "                                      max_features='log2',\n",
    "                                      max_leaf_nodes=6,\n",
    "                                      n_estimators=100)\n",
    "model_random.fit(X_train, y_train)\n",
    "y_pred_rand = model.predict(X_test)\n",
    "print(classification_report(y_pred_rand, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
