{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55e6b84",
   "metadata": {},
   "source": [
    "# **Introduction to Scikit-learn**\n",
    "\n",
    "---\n",
    "\n",
    "### üîç **What is Scikit-learn?**\n",
    "\n",
    "**Scikit-learn** (also written as `sklearn`) is one of the **most popular Machine Learning libraries** in Python. It provides **simple and efficient tools** for:\n",
    "\n",
    "‚úÖ Data Preprocessing\n",
    "‚úÖ Classification (like spam detection)\n",
    "‚úÖ Regression (like predicting house prices)\n",
    "‚úÖ Clustering (like customer segmentation)\n",
    "‚úÖ Dimensionality Reduction (like PCA)\n",
    "‚úÖ Model Selection and Evaluation\n",
    "\n",
    "---\n",
    "\n",
    "### ü§ñ Why Use Scikit-learn?\n",
    "\n",
    "* **Beginner-friendly syntax**\n",
    "* Built on top of powerful libraries like **NumPy**, **SciPy**, and **matplotlib**\n",
    "* Offers **ready-to-use algorithms** (you don‚Äôt need to code them from scratch!)\n",
    "* Ideal for **prototyping and experimenting** with models\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è How it Works (Basic Workflow)\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load data\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Step 2: Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Step 3: Choose and train a model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions and evaluate\n",
    "predictions = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üåü Real-Life Example Use Cases\n",
    "\n",
    "* **Email filtering** (classify spam vs. non-spam)\n",
    "* **Credit scoring** (predict default risk)\n",
    "* **Recommendation systems** (like movies or shopping)\n",
    "* **Health diagnostics** (predict diseases)\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Installation\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f8f826",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## üï∞Ô∏è **History of Scikit-learn**\n",
    "\n",
    "### üîπ **Origin:**\n",
    "\n",
    "* Scikit-learn began as a **Google Summer of Code project in 2007**.\n",
    "* It was originally developed by **David Cournapeau** as part of the **SciKits** project ‚Äî ‚Äú**Sci**entific tool**kits**‚Äù built on **SciPy**.\n",
    "\n",
    "### üîπ **First Release:**\n",
    "\n",
    "* The **first official release** of Scikit-learn (version 0.1) came in **February 2010**.\n",
    "* Major contributions for that release were made by **Fabian Pedregosa**, **Ga√´l Varoquaux**, **Alexandre Gramfort**, and others from **INRIA** (a French research institute).\n",
    "\n",
    "### üîπ **Why the name \"Scikit-learn\"?**\n",
    "\n",
    "* ‚Äú**SciKit**‚Äù = SciPy Toolkit\n",
    "* ‚Äú**learn**‚Äù = Machine learning functionality\n",
    "  So, `scikit-learn` = A SciPy toolkit for learning algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà **Growth Over Time**\n",
    "\n",
    "* üîπ Initially focused on **basic models** like linear regression and k-means.\n",
    "* üîπ Over the years, added advanced models like **random forests, gradient boosting, pipelines, and cross-validation** tools.\n",
    "* üîπ It‚Äôs now one of the **most widely used** ML libraries in **academia, research, and industry**.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **Philosophy Behind Scikit-learn**\n",
    "\n",
    "* **Simplicity**: Easy to use, consistent APIs\n",
    "* **Efficiency**: Built on top of **NumPy**, **SciPy**, and **joblib**\n",
    "* **Interoperability**: Works well with **Pandas**, **Matplotlib**, and other Python libraries\n",
    "* **Stability**: No breaking changes across updates without good reason\n",
    "\n",
    "---\n",
    "\n",
    "## üë• **Community and Development**\n",
    "\n",
    "* Open-source and actively developed on GitHub\n",
    "* Thousands of contributors worldwide\n",
    "* Supported by the **Python Software Foundation**, **INRIA**, and the **NumFOCUS** foundation\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Fun Fact\n",
    "\n",
    "Despite being widely used, Scikit-learn is **not designed for deep learning** ‚Äî instead, it‚Äôs focused on **classical machine learning**. For deep learning, libraries like **TensorFlow** and **PyTorch** are used.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2925744c",
   "metadata": {},
   "source": [
    "üéØ Scikit-learn (`sklearn`) follows a **very simple and powerful 3-step process** for any machine learning task:\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **3 Main Steps in Scikit-learn**\n",
    "\n",
    "### ‚úÖ 1. **Import & Prepare the Data**\n",
    "\n",
    "* Load your dataset\n",
    "* Preprocess if needed (scaling, encoding, etc.)\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "X, y = load_iris(return_X_y=True)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 2. **Choose & Train the Model**\n",
    "\n",
    "* Select a machine learning algorithm\n",
    "* Fit it to your training data\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ 3. **Predict & Evaluate**\n",
    "\n",
    "* Make predictions on new data\n",
    "* Measure accuracy or performance\n",
    "\n",
    "```python\n",
    "predictions = model.predict(X)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y, predictions))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ In short:\n",
    "\n",
    "```\n",
    "Step 1: Prepare\n",
    "Step 2: Train\n",
    "Step 3: Predict & Evaluate\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a155e77",
   "metadata": {},
   "source": [
    "# **Types of Learning in Machine Learning**\n",
    "---\n",
    "\n",
    "## üß† **1. Supervised Learning**\n",
    "\n",
    "\n",
    "In **supervised learning**, the model is trained on a **labeled dataset** ‚Äî meaning, each input comes with a known output (target).\n",
    "The goal is to learn a mapping from **inputs (X)** to **outputs (y)**.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Real-Life Examples:\n",
    "\n",
    "| Example                | Input (X)                    | Output (y)       |\n",
    "| ---------------------- | ---------------------------- | ---------------- |\n",
    "| Email spam filter      | Email text                   | Spam or Not Spam |\n",
    "| House price prediction | Features like size, location | House price      |\n",
    "| Disease diagnosis      | Patient symptoms             | Disease name     |\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Types:\n",
    "\n",
    "* **Regression**: Predict a continuous value\n",
    "  *e.g., house price, temperature*\n",
    "\n",
    "  ```python\n",
    "  from sklearn.linear_model import LinearRegression\n",
    "  model = LinearRegression()\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "* **Classification**: Predict a category or class\n",
    "  *e.g., pass/fail, cat/dog, positive/negative*\n",
    "\n",
    "  ```python\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  model = DecisionTreeClassifier()\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "#### üîß Common Algorithms:\n",
    "\n",
    "* Linear Regression\n",
    "* Decision Trees\n",
    "* Random Forest\n",
    "* Support Vector Machines (SVM)\n",
    "* k-Nearest Neighbors (KNN)\n",
    "---\n",
    "\n",
    "### ‚úÖ Advantages:\n",
    "\n",
    "* Easy to evaluate using accuracy, RMSE, etc.\n",
    "* Clear objective: minimize the error between prediction and truth\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Challenges:\n",
    "\n",
    "* Needs a **large amount of labeled data**\n",
    "* Poor generalization if data is biased or overfitted\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **2. Unsupervised Learning**üîç \n",
    "\n",
    "In **unsupervised learning**, there are **no labels**. The algorithm tries to discover patterns, relationships, or structures in the data.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Real-Life Examples:\n",
    "\n",
    "| Example               | Goal                                  |\n",
    "| --------------------- | ------------------------------------- |\n",
    "| Customer segmentation | Group similar customers for marketing |\n",
    "| Topic modeling        | Group similar articles or documents   |\n",
    "| Anomaly detection     | Find unusual patterns (e.g., fraud)   |\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Types:\n",
    "\n",
    "* **Clustering**: Group data points based on similarity\n",
    "  *e.g., K-Means, DBSCAN*\n",
    "\n",
    "  ```python\n",
    "  from sklearn.cluster import KMeans\n",
    "  model = KMeans(n_clusters=3)\n",
    "  model.fit(X_data)\n",
    "  ```\n",
    "\n",
    "* **Dimensionality Reduction**: Reduce features while keeping important info\n",
    "  *e.g., PCA, t-SNE*\n",
    "\n",
    "  ```python\n",
    "  from sklearn.decomposition import PCA\n",
    "  pca = PCA(n_components=2)\n",
    "  X_pca = pca.fit_transform(X_data)\n",
    "  ```\n",
    "\n",
    "\n",
    "#### üîß Common Algorithms:\n",
    "\n",
    "* K-Means Clustering\n",
    "* Hierarchical Clustering\n",
    "* PCA (Principal Component Analysis)\n",
    "---\n",
    "\n",
    "### ‚úÖ Advantages:\n",
    "\n",
    "* Works without labeled data (easier to collect)\n",
    "* Useful for **exploratory data analysis**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Challenges:\n",
    "\n",
    "* Hard to evaluate results\n",
    "* Clustering results can vary based on algorithm and parameters\n",
    "\n",
    "---\n",
    "\n",
    "## üß† **3. Reinforcement Learning** (RL)\n",
    "\n",
    "\n",
    "In **reinforcement learning**, an **agent** learns by interacting with an **environment**.\n",
    "It gets **rewards** or **penalties** and learns to take actions that maximize rewards over time.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Real-Life Examples:\n",
    "\n",
    "| Example          | Agent       | Environment       |\n",
    "| ---------------- | ----------- | ----------------- |\n",
    "| Self-driving car | The car     | Roads, traffic    |\n",
    "| Game playing     | AI bot      | Chess, Go board   |\n",
    "| Industrial robot | Robotic arm | Factory workspace |\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Key Concepts:\n",
    "\n",
    "* **Agent**: Learner (e.g., robot)\n",
    "* **Environment**: Where agent operates\n",
    "* **Action**: What the agent does\n",
    "* **Reward**: Feedback (positive or negative)\n",
    "* **Policy**: Strategy the agent uses\n",
    "\n",
    "---\n",
    "#### üîß Common Algorithms:\n",
    "\n",
    "* Q-Learning\n",
    "* Deep Q Networks (DQN)\n",
    "* Policy Gradient methods\n",
    "---\n",
    "\n",
    "### ‚ùå Not in Scikit-learn\n",
    "\n",
    "Scikit-learn is **not designed for RL**. You would use:\n",
    "\n",
    "* `OpenAI Gym` for environment simulation\n",
    "* `Stable-Baselines3`, `Ray RLlib`, or `TensorFlow`/`PyTorch` for RL algorithms\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è **Comparison Table**\n",
    "\n",
    "| Feature      | Supervised             | Unsupervised          | Reinforcement    |\n",
    "| ------------ | ---------------------- | --------------------- | ---------------- |\n",
    "| Labeled Data | ‚úÖ Yes                  | ‚ùå No                  | ‚úÖ Reward signals |\n",
    "| Goal         | Predict outcome        | Find structure        | Maximize reward  |\n",
    "| Example      | Email spam detection   | Customer segmentation | Playing chess    |\n",
    "| Algorithms   | Linear Regression, SVM | K-Means, PCA          | Q-Learning, DQN  |\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Bonus Types\n",
    "\n",
    "### üî∏ **Semi-Supervised Learning**\n",
    "\n",
    "* Uses **a small amount of labeled data + a large amount of unlabeled data**\n",
    "* Used in real-world tasks like **image classification**, where labeling is expensive\n",
    "\n",
    "### üî∏ **Self-Supervised Learning**\n",
    "\n",
    "* No external labels; the model generates its own labels from data\n",
    "* Used in **natural language processing** and **foundation models** (e.g., ChatGPT)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba99eb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## üîÑ **Scikit-learn Workflow (Machine Learning Lifecycle)**\n",
    "\n",
    "Scikit-learn makes it easy to follow a **standard workflow** for building ML models. Here‚Äôs the **typical step-by-step process**:\n",
    "\n",
    "---\n",
    "\n",
    "### üî¢ **1. Load the Dataset**\n",
    "\n",
    "You can load built-in datasets or your own CSV/data files.\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üßº **2. Data Preprocessing (Very Important)**\n",
    "\n",
    "**Data preprocessing** is the process of **cleaning and preparing data** to make it suitable for a machine learning model.\n",
    "\n",
    "#### üß© Why Preprocess?\n",
    "\n",
    "* To handle **missing values**\n",
    "* To convert **text into numbers**\n",
    "* To **scale/normalize** numerical data\n",
    "* To prepare data for **better model performance**\n",
    "\n",
    "---\n",
    "\n",
    "### üßπ Key Preprocessing Techniques in Scikit-learn:\n",
    "\n",
    "#### ‚úÖ A. **Handling Missing Values**\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ B. **Feature Scaling (Normalization/Standardization)**\n",
    "\n",
    "* Scaling ensures all features contribute equally to model learning.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ C. **Encoding Categorical Variables**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "```\n",
    "\n",
    "For multiple categories (one-hot encoding):\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "X_encoded = encoder.fit_transform(X_categorical).toarray()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ D. **Splitting Data**\n",
    "\n",
    "Split your dataset into training and testing parts.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üß† **3. Choose and Train a Model**\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üîÆ **4. Make Predictions**\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìä **5. Evaluate the Model**\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary of Scikit-learn Workflow:\n",
    "\n",
    "```text\n",
    "1. Load Data\n",
    "2. Preprocess the Data\n",
    "3. Split into Train/Test\n",
    "4. Choose Model\n",
    "5. Train the Model\n",
    "6. Predict\n",
    "7. Evaluate\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b3fd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
